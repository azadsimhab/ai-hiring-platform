from pydantic import BaseModel, Field, HttpUrl
from typing import List, Optional, Any, Dict
from datetime import datetime
from app.models.multimodal_screening import InterviewStatus, SessionType, ResponseStatus

# --- ResponseEvaluation Schemas ---

class ResponseEvaluationBase(BaseModel):
    relevance_score: Optional[float] = Field(None, ge=0, le=100, description="How relevant the answer was to the question.", example=85.5)
    clarity_score: Optional[float] = Field(None, ge=0, le=100, description="Clarity of the candidate's communication.", example=92.0)
    sentiment_score: Optional[float] = Field(None, ge=-1, le=1, description="Sentiment of the response (-1 negative, 1 positive).", example=0.8)
    confidence_score: Optional[float] = Field(None, ge=0, le=100, description="Candidate's perceived confidence.", example=88.0)
    keyword_matches: Optional[List[str]] = Field(None, description="Keywords matched from the ideal answer.", example=["teamwork", "leadership"])
    ai_feedback: Optional[str] = Field(None, description="Qualitative feedback generated by AI.", example="The candidate provided a clear, structured answer...")
    ai_generated: bool = Field(True, description="Indicates if the evaluation was AI-generated.")

class ResponseEvaluationCreate(ResponseEvaluationBase):
    candidate_response_id: int = Field(..., description="The ID of the candidate response being evaluated.")

class ResponseEvaluationUpdate(BaseModel):
    relevance_score: Optional[float] = Field(None, ge=0, le=100)
    clarity_score: Optional[float] = Field(None, ge=0, le=100)
    sentiment_score: Optional[float] = Field(None, ge=-1, le=1)
    confidence_score: Optional[float] = Field(None, ge=0, le=100)
    keyword_matches: Optional[List[str]] = None
    ai_feedback: Optional[str] = None

class ResponseEvaluationResponse(ResponseEvaluationBase):
    id: int
    candidate_response_id: int
    created_at: datetime

    class Config:
        orm_mode = True
        use_enum_values = True

# --- CandidateResponse Schemas ---

class CandidateResponseBase(BaseModel):
    response_text: Optional[str] = Field(None, description="Transcribed text from the candidate's audio response.")
    audio_url: Optional[HttpUrl] = Field(None, description="URL to the stored audio file of the response.")
    video_url: Optional[HttpUrl] = Field(None, description="URL to the stored video file of the response.")
    processing_status: ResponseStatus = Field(ResponseStatus.pending, description="The processing status of the response.")
    processing_error: Optional[str] = Field(None, description="Details of any processing error.")

class CandidateResponseCreate(BaseModel):
    screening_question_id: int = Field(..., description="The ID of the screening question this is a response to.")
    # The audio/video data will be handled as a file upload in the endpoint, not in this schema.

class CandidateResponseUpdate(BaseModel):
    response_text: Optional[str] = None
    processing_status: Optional[ResponseStatus] = None
    processing_error: Optional[str] = None

class CandidateResponseResponse(CandidateResponseBase):
    id: int
    screening_question_id: int
    created_at: datetime
    updated_at: Optional[datetime] = None
    evaluation: Optional[ResponseEvaluationResponse] = None

    class Config:
        orm_mode = True
        use_enum_values = True

# --- ScreeningQuestion Schemas ---

class ScreeningQuestionBase(BaseModel):
    question_text: str = Field(..., description="The text of the screening question.")
    question_type: str = Field(..., description="Type of question (e.g., 'behavioral', 'technical', 'follow_up').", example="behavioral")
    order: int = Field(..., description="The sequence number of the question in the interview.", example=1)

class ScreeningQuestionCreate(ScreeningQuestionBase):
    interview_session_id: int
    original_question_id: Optional[int] = None

class ScreeningQuestionResponse(ScreeningQuestionBase):
    id: int
    interview_session_id: int
    original_question_id: Optional[int] = None
    created_at: datetime
    candidate_response: Optional[CandidateResponseResponse] = None

    class Config:
        orm_mode = True
        use_enum_values = True

# --- InterviewSession Schemas ---

class InterviewSessionBase(BaseModel):
    candidate_profile_id: int = Field(..., description="ID of the candidate being interviewed.")
    job_description_id: int = Field(..., description="ID of the job description for the interview.")
    status: InterviewStatus = Field(InterviewStatus.scheduled, description="The current status of the interview session.")
    session_type: SessionType = Field(SessionType.ai_only, description="The type of interview session.")
    scheduled_time: Optional[datetime] = Field(None, description="The scheduled start time for the interview.")
    human_notes: Optional[str] = Field(None, description="Notes from a human reviewer, if applicable.")

class InterviewSessionCreate(BaseModel):
    candidate_profile_id: int = Field(..., description="ID of the candidate to be interviewed.")
    job_description_id: int = Field(..., description="ID of the job description to interview for.")
    session_type: Optional[SessionType] = Field(SessionType.ai_only, description="Type of interview session.")
    scheduled_time: Optional[datetime] = Field(None, description="Optional scheduled time for the interview.")
    # Allow specifying a list of pre-generated question IDs to use
    question_ids: Optional[List[int]] = Field(None, description="List of specific question IDs to include in the session.")

class InterviewSessionUpdate(BaseModel):
    status: Optional[InterviewStatus] = None
    human_notes: Optional[str] = None
    overall_ai_evaluation: Optional[Dict[str, Any]] = None

class InterviewSessionResponse(InterviewSessionBase):
    id: int
    started_at: Optional[datetime] = None
    ended_at: Optional[datetime] = None
    overall_ai_evaluation: Optional[Dict[str, Any]] = Field(None, description="A summary evaluation of the entire interview performance.")
    created_at: datetime
    updated_at: Optional[datetime] = None

    class Config:
        orm_mode = True
        use_enum_values = True

# --- Detailed/Composite Schemas ---

class InterviewSessionDetailResponse(InterviewSessionResponse):
    """A comprehensive view of an interview session, including all related data."""
    # Import here to avoid circular dependencies at module level
    from app.schemas.resume_scanner import CandidateProfileResponse
    from app.schemas.jd_generator import JobDescriptionResponse

    candidate_profile: Optional[CandidateProfileResponse] = None
    job_description: Optional[JobDescriptionResponse] = None
    screening_questions: List[ScreeningQuestionResponse] = []

    class Config:
        orm_mode = True
        use_enum_values = True

# --- Special Request/Response Schemas for API Endpoints ---

class StartInterviewRequest(BaseModel):
    candidate_profile_id: int
    job_description_id: int
    session_type: Optional[SessionType] = SessionType.ai_only
    num_questions: Optional[int] = Field(5, ge=1, le=20, description="Number of questions to generate if not specified by IDs.")
    question_types: Optional[List[str]] = Field(["behavioral", "technical"], description="Types of questions to generate.")

class StartInterviewResponse(BaseModel):
    interview_session_id: int
    status: InterviewStatus
    first_question: ScreeningQuestionResponse

class SubmitResponseRequest(BaseModel):
    interview_session_id: int
    screening_question_id: int
    # The audio/video file is sent as form data, not in the JSON body

class SubmitResponseResponse(BaseModel):
    message: str = "Response submitted successfully. Processing has started."
    next_question: Optional[ScreeningQuestionResponse] = None
    interview_completed: bool = False

class EndInterviewResponse(BaseModel):
    interview_session_id: int
    message: str = "Interview session completed."
    final_status: InterviewStatus
    evaluation_url: HttpUrl # A URL to poll for the final evaluation results

class InterviewEvaluationSummary(BaseModel):
    """The final, overall evaluation of an interview session."""
    overall_score: float = Field(..., ge=0, le=100, description="A single, aggregated score for the interview.")
    communication_score: float = Field(..., ge=0, le=100)
    technical_score: float = Field(..., ge=0, le=100)
    behavioral_score: float = Field(..., ge=0, le=100)
    summary: str = Field(..., description="A high-level text summary of the candidate's performance.")
    key_strengths: List[str]
    areas_for_improvement: List[str]
